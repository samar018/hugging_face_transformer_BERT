{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V5E1","authorship_tag":"ABX9TyO1SfUcLiQOVtkaaJxHQg2u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"79fe3c6771564e42ad9917be30714b0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_287d3805963d45e89f2a340abbe8be64","IPY_MODEL_1065e87dbe474d0f87967c3028138b05","IPY_MODEL_56ba94ab1fd542f99a3078b110cba155"],"layout":"IPY_MODEL_c8fc0d42889a4720880261eb8df29065"}},"287d3805963d45e89f2a340abbe8be64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03605d3174e3478abce47d0e28eed1f6","placeholder":"​","style":"IPY_MODEL_71e37f8758dc4251b7262905539c70c2","value":"Map: 100%"}},"1065e87dbe474d0f87967c3028138b05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcd3ebcbb2284ea39cd07efec48f482f","max":10570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39ed1a2503bd4d889d92642b9725f9a5","value":10570}},"56ba94ab1fd542f99a3078b110cba155":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d484eec4e40439bad8714dddc4c08ea","placeholder":"​","style":"IPY_MODEL_565e5b960afb4cd68b3a94a08d490471","value":" 10570/10570 [00:51&lt;00:00, 223.53 examples/s]"}},"c8fc0d42889a4720880261eb8df29065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03605d3174e3478abce47d0e28eed1f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71e37f8758dc4251b7262905539c70c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcd3ebcbb2284ea39cd07efec48f482f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39ed1a2503bd4d889d92642b9725f9a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d484eec4e40439bad8714dddc4c08ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"565e5b960afb4cd68b3a94a08d490471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oavKnAPfG7ly","executionInfo":{"status":"ok","timestamp":1757857862467,"user_tz":-360,"elapsed":21501,"user":{"displayName":"samar das","userId":"00788054152370929322"}}},"outputs":[],"source":["# Colab: install latest libs and disable W&B prompt\n","!pip install --upgrade -q transformers datasets evaluate\n","\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"   # disables wandb login prompt\n"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# Load SQuAD v1.1 dataset\n","dataset = load_dataset(\"squad\")\n","\n","# Print one sample\n","print(dataset[\"train\"][0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgHtAafuHIT-","executionInfo":{"status":"ok","timestamp":1757857874274,"user_tz":-360,"elapsed":11510,"user":{"displayName":"samar das","userId":"00788054152370929322"}},"outputId":"20a9a338-7b23-440b-e0e4-cab4faf94a60"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","def preprocess_function(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    tokenized = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=384,\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\"\n","    )\n","\n","    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n","    offset_mapping = tokenized[\"offset_mapping\"]\n","\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        input_ids = tokenized[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","        sample_index = sample_mapping[i]\n","        answer = examples[\"answers\"][sample_index]\n","\n","        if len(answer[\"answer_start\"]) == 0:\n","            start_positions.append(cls_index)\n","            end_positions.append(cls_index)\n","        else:\n","            start_char = answer[\"answer_start\"][0]\n","            end_char = start_char + len(answer[\"text\"][0])\n","            sequence_ids = tokenized.sequence_ids(i)\n","\n","            # find context start and end\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != 1:\n","                token_start_index += 1\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != 1:\n","                token_end_index -= 1\n","\n","            # if answer not in span → CLS\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                start_positions.append(cls_index)\n","                end_positions.append(cls_index)\n","            else:\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                start_positions.append(token_start_index - 1)\n","\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                end_positions.append(token_end_index + 1)\n","\n","    tokenized[\"start_positions\"] = start_positions\n","    tokenized[\"end_positions\"] = end_positions\n","    return tokenized\n","\n","tokenized_datasets = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=dataset[\"train\"].column_names\n",")\n","\n","print(tokenized_datasets)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242,"referenced_widgets":["79fe3c6771564e42ad9917be30714b0e","287d3805963d45e89f2a340abbe8be64","1065e87dbe474d0f87967c3028138b05","56ba94ab1fd542f99a3078b110cba155","c8fc0d42889a4720880261eb8df29065","03605d3174e3478abce47d0e28eed1f6","71e37f8758dc4251b7262905539c70c2","dcd3ebcbb2284ea39cd07efec48f482f","39ed1a2503bd4d889d92642b9725f9a5","0d484eec4e40439bad8714dddc4c08ea","565e5b960afb4cd68b3a94a08d490471"]},"id":"HmYO2ZbjHKbu","executionInfo":{"status":"ok","timestamp":1757857961715,"user_tz":-360,"elapsed":87435,"user":{"displayName":"samar das","userId":"00788054152370929322"}},"outputId":"641ad7e2-3208-4cd3-a6fb-56e13e8a8439"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79fe3c6771564e42ad9917be30714b0e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n","        num_rows: 88524\n","    })\n","    validation: Dataset({\n","        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'start_positions', 'end_positions'],\n","        num_rows: 10784\n","    })\n","})\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForQuestionAnswering\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQdcCNbIHR50","executionInfo":{"status":"ok","timestamp":1757857983010,"user_tz":-360,"elapsed":21273,"user":{"displayName":"samar das","userId":"00788054152370929322"}},"outputId":"5e2bf299-b5d6-4394-b4ee-abf23943650e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./qa-bert\",\n","    eval_strategy=\"epoch\",   # evaluate once per epoch\n","    learning_rate=3e-5,\n","    per_device_train_batch_size=8,  # Reduced batch size\n","    per_device_eval_batch_size=8,   # Reduced batch size\n","    num_train_epochs=2,   # you can change to 3\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    logging_steps=100,\n","    optim=\"adamw_torch\" # Disable fused optimizer\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"].select(range(200)), # Further reduced data\n","    eval_dataset=tokenized_datasets[\"validation\"].select(range(200)), # Further reduced data\n","    tokenizer=tokenizer\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"HqZ9lSrjPDT1","outputId":"185eedca-724a-4809-9a22-c41de9b01445"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/tmp/ipython-input-1525408514.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/50 06:14 < 23:42, 0.03 it/s, Epoch 0.44/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import evaluate\n","from collections import OrderedDict, defaultdict\n","\n","metric = evaluate.load(\"squad\")\n","\n","# Postprocess predictions: logits → text spans\n","def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n","    all_start_logits, all_end_logits = raw_predictions\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    predictions = OrderedDict()\n","    for example_index, example in enumerate(examples):\n","        feature_indices = features_per_example[example_index]\n","        context = example[\"context\"]\n","        prelim_predictions = []\n","\n","        for feature_index in feature_indices:\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","\n","            start_indexes = np.argsort(start_logits)[-1: -n_best_size-1: -1].tolist()\n","            end_indexes = np.argsort(end_logits)[-1: -n_best_size-1: -1].tolist()\n","\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    if start_index >= len(offset_mapping) or end_index >= len(offset_mapping):\n","                        continue\n","                    if offset_mapping[start_index] is None or offset_mapping[end_index] is None:\n","                        continue\n","                    if end_index < start_index:\n","                        continue\n","                    length = offset_mapping[end_index][1] - offset_mapping[start_index][0]\n","                    if length > max_answer_length:\n","                        continue\n","\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    score = start_logits[start_index] + end_logits[end_index]\n","\n","                    prelim_predictions.append({\n","                        \"score\": score,\n","                        \"start_char\": start_char,\n","                        \"end_char\": end_char\n","                    })\n","\n","        if len(prelim_predictions) == 0:\n","            predictions[example[\"id\"]] = \"\"\n","        else:\n","            best = sorted(prelim_predictions, key=lambda x: x[\"score\"], reverse=True)[0]\n","            predictions[example[\"id\"]] = context[best[\"start_char\"]: best[\"end_char\"]]\n","\n","    return predictions\n","\n","# Run predictions\n","raw_pred = trainer.predict(tokenized_datasets[\"validation\"])\n","start_logits, end_logits = raw_pred.predictions[:2]\n","\n","# Prepare features for validation (with offsets)\n","def prepare_validation_features(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    tokenized = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        truncation=\"only_second\",\n","        max_length=384,\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\"\n","    )\n","    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n","    tokenized[\"example_id\"] = []\n","    for i in range(len(tokenized[\"input_ids\"])):\n","        sample_index = sample_mapping[i]\n","        tokenized[\"example_id\"].append(examples[\"id\"][sample_index])\n","    return tokenized\n","\n","validation_features = dataset[\"validation\"].map(\n","    prepare_validation_features,\n","    batched=True,\n","    remove_columns=dataset[\"validation\"].column_names\n",")\n","\n","# Get final predictions\n","final_predictions = postprocess_qa_predictions(\n","    dataset[\"validation\"], validation_features, (start_logits, end_logits)\n",")\n","\n","# Format for metrics\n","preds = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n","refs = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in dataset[\"validation\"]]\n","\n","# Compute EM + F1\n","metrics = metric.compute(predictions=preds, references=refs)\n","print(\"Evaluation metrics:\", metrics)\n"],"metadata":{"id":"S3xuVK-4sM8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def answer_question(question, context):\n","    inputs = tokenizer(question, context, return_tensors=\"pt\")\n","    outputs = model(**inputs)\n","    start = outputs.start_logits.argmax()\n","    end = outputs.end_logits.argmax()\n","    answer_ids = inputs[\"input_ids\"][0][start:end+1]\n","    return tokenizer.decode(answer_ids, skip_special_tokens=True)\n","\n","# Test 1\n","q1 = \"Who developed the theory of relativity?\"\n","c1 = \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n","print(\"Q1:\", q1)\n","print(\"A1:\", answer_question(q1, c1))\n","\n","# Test 2\n","q2 = \"What is the capital of France?\"\n","c2 = \"France is a country in Europe. Its capital city is Paris, known for the Eiffel Tower.\"\n","print(\"Q2:\", q2)\n","print(\"A2:\", answer_question(q2, c2))\n"],"metadata":{"id":"JGJJ4R1qsjE8"},"execution_count":null,"outputs":[]}]}